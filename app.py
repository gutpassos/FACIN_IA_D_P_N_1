# Projeto 7 - V4 - Gerenciamento de Mem√≥ria e Contexto - Sistema de Multi-Agentes de IA com LangGraph Para Automa√ß√£o da Folha e Consulta a Banco de Dados

# Importa a biblioteca os para manipula√ß√£o de vari√°veis e caminhos do sistema operacional
import os

# Importa o Streamlit para cria√ß√£o de interface web interativa
import streamlit as st

# Importa sqlite3 para intera√ß√£o com banco de dados SQLite
import sqlite3 

# Importa operator para opera√ß√µes funcionais em estruturas de dados
import operator

# Importa a fun√ß√£o load_dotenv para carregar vari√°veis de ambiente de um arquivo .env
from dotenv import load_dotenv

# Importa Annotated, List e TypedDict para anota√ß√µes de tipos avan√ßados em Python
from typing import Annotated, List, TypedDict

# Importa o cliente ChatGroq para realizar chamadas ao modelo Groq
from langchain_groq import ChatGroq

# Importa o cliente ChatOpenAI para realizar chamadas ao modelo da OpenAI
from langchain_openai import ChatOpenAI

# Importa classes de mensagem do LangChain para estruturar comunica√ß√µes entre agentes
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage

# Importa ferramentas de template de prompt do LangChain para construir conversas
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# Importa a classe StateGraph e constantes de in√≠cio/fim para defini√ß√£o de grafos de estados
from langgraph.graph import StateGraph, END, START

# Importa n√≥s de ferramenta predefinidos para uso dentro do grafo de estados
from langgraph.prebuilt import ToolNode

# Importa o decorador tool para registrar fun√ß√µes como ferramentas de agente
from langchain.tools import tool

# Define o nome do arquivo que ser√° utilizado como banco de dados SQLite
DB_FILE = "folha_pagamento.db" 

# Configura o layout da p√°gina no Streamlit com t√≠tulo, √≠cone e largura do layout
st.set_page_config(page_title="Conversa com a Folha", page_icon=":100:", layout="wide")

# Exibe os t√≠tulos 
st.title("Conversa com a Folha de Pagamento - V4")
st.title("ü§ñ Gerenciamento de Mem√≥ria e Contexto - Sistema Multi-Agentes de IA com LangGraph Para Automa√ß√£o da Folha de Pagamento e Consulta a Banco de Dados")

# Carrega vari√°veis de ambiente definidas em arquivo .env
#load_dotenv()

# Obt√©m a chave da API Groq das vari√°veis de ambiente ou usa string vazia como padr√£o
#groq_api_key = os.getenv("GROQ_API_KEY", "")

# Obt√©m a chave da API OpenAI das vari√°veis de ambiente ou usa string vazia como padr√£o
#openai_api_key = os.getenv("OPENAI_API_KEY", "")

# Cria um campo na barra lateral para inserir a chave Groq, ocultando o valor digitado
groq_api_key = st.sidebar.text_input("üîë Groq API Key", type="password", placeholder="cole sua chave aqui")

# Cria um campo na barra lateral para inserir a chave OpenAI, ocultando o valor digitado
openai_api_key = st.sidebar.text_input("üîë OpenAI API Key", type="password", placeholder="cole sua chave aqui")

# Verifica se ambas as chaves foram fornecidas; se n√£o, exibe alerta e interrompe a execu√ß√£o
if not groq_api_key or not openai_api_key:

    # Exibe um aviso informando que √© necess√°rio definir ambas as chaves para continuar
    st.warning("‚ö†Ô∏è Defina ambas as chaves Groq e OpenAI na barra lateral para continuar.")

    # Interrompe a execu√ß√£o do aplicativo at√© que as chaves sejam definidas
    st.stop()

# Define um tipo de dicion√°rio para representar o estado do agente com tipagem est√°tica
class AgentState(TypedDict):

    # Declara o campo 'messages' como uma lista de BaseMessage, agregada pelo operador de soma
    messages: Annotated[List[BaseMessage], operator.add]

# Registra a fun√ß√£o como ferramenta utiliz√°vel pelos agentes
@tool
# Define a fun√ß√£o query_folha_database, que recebe uma string de consulta SQL e retorna uma string com o resultado
def query_folha_database(sql_query: str) -> str:
    # Docstring que descreve o comportamento e uso da ferramenta
    """
    Executa uma consulta SQL SOMENTE do tipo SELECT no banco de dados Folha de Folha de Pagamento SQLite
    e retorna os resultados.
    Usamos esta ferramenta para obter informa√ß√µes sobre Servidores ou remunera√ß√µes.
    Tabelas dispon√≠veis:
    1. tb_servidores (colunas: id, nome, cpf, matricula, orgao, cargo)
    2. tb_folha_pagamento (colunas: id, matricula, competencia, vencimentos, descontos, liquido)
    Importante: Forne√ßa APENAS consultas SQL `SELECT`. N√£o use `UPDATE`, `DELETE`, `INSERT` ou `DROP`.
    Exemplo de consulta SQL v√°lida:
    'SELECT nome, liquido, descontos, vencimentos FROM tb_servidores s JOIN tb_folha_pagamento f ON s.matricula = f.matricula WHERE orgao = 'Secretaria da Sa√∫de';'
    'SELECT competencia, vencimentos, descontos, liquido FROM tb_servidores s JOIN tb_folha_pagamento f ON f.matricula = s.matricula WHERE nome = 'Servidor 3' ORDER BY competencia DESC;'
    'SELECT COUNT(DISTINCT f1.matricula) AS total_servidores_com_aumento FROM tb_folha_pagamento AS f1 WHERE f1.vencimentos > (SELECT f2.vencimentos FROM tb_folha_pagamento AS f2 WHERE f2.matricula = f1.matricula AND f2.competencia < f1.competencia ORDER BY f2.competencia DESC LIMIT 1 );'
     """
    # Exibe no console a query recebida para fins de debug
    print(f"--- Ferramenta query_folha_database recebendo SQL: {sql_query} ---")

    # Verifica se a consulta come√ßa com SELECT, garantindo seguran√ßa
    if not sql_query.strip().upper().startswith("SELECT"):

        # Em caso de tentativa de SQL n√£o-SELECT, exibe erro de seguran√ßa
        print("!!! ERRO DE SEGURAN√áA: Tentativa de executar SQL n√£o-SELECT !!!")

        # Retorna mensagem de erro ao usu√°rio
        return "Erro: Esta ferramenta s√≥ pode executar consultas SELECT."

    # Inicializa a vari√°vel de conex√£o como None
    conn = None

    # Bloco principal de execu√ß√£o da consulta SQL
    try:

        # Verifica se o arquivo de banco de dados existe antes de conectar
        if not os.path.exists(DB_FILE):

             # Retorna mensagem de erro se o arquivo n√£o foi encontrado
             return f"Erro: Arquivo do banco de dados '{DB_FILE}' n√£o encontrado. Execute o script 'create_folha_db.py' primeiro."

        # Abre conex√£o com o banco de dados SQLite
        conn = sqlite3.connect(DB_FILE)

        # Cria um cursor para executar comandos SQL
        cursor = conn.cursor()

        # Executa a consulta SQL recebida
        cursor.execute(sql_query)

        # Busca todos os resultados retornados pela consulta
        results = cursor.fetchall()

        # Caso n√£o haja resultados, informa ao usu√°rio
        if not results:

            return "Nenhum resultado encontrado para a consulta."

        else:

            # Obt√©m os nomes das colunas a partir da descri√ß√£o do cursor
            column_names = [description[0] for description in cursor.description]

            # Cria um cabe√ßalho com nomes de colunas separados por " | "
            header = " | ".join(column_names)

            # Converte cada linha de resultados em string, separando campos por " | "
            rows_str = [" | ".join(map(str, row)) for row in results]

            # Define n√∫mero m√°ximo de resultados a exibir
            max_results = 15

            # Monta a sa√≠da inicial com quantidade de registros e cabe√ßalho
            output = f"Resultados da consulta ({len(results)} encontrados):\n{header}\n" + "\n".join(rows_str[:max_results])

            # Se houver mais resultados que o limite, adiciona informa√ß√£o de omiss√£o
            if len(results) > max_results:
                output += f"\n... (mais {len(results) - max_results} resultados omitidos)"

            # Retorna a string formatada com os resultados da consulta
            return output

    # Captura erros espec√≠ficos de SQLite
    except sqlite3.Error as e:
        
        # Exibe mensagem de erro SQL no console para debug
        print(f"!!! ERRO SQL: {e} ao executar '{sql_query}' !!!")
        
        # Retorna mensagem de erro ao usu√°rio com detalhes do SQLite
        return f"Erro ao executar a consulta SQL: {e}. Verifique a sintaxe da sua consulta e os nomes das tabelas/colunas."
   
    # Captura quaisquer outras exce√ß√µes inesperadas
    except Exception as e:

        # Exibe mensagem gen√©rica de erro no console para debug
        print(f"!!! ERRO Inesperado na ferramenta: {e} !!!")
        
        # Retorna mensagem de erro gen√©rico ao usu√°rio
        return f"Ocorreu um erro inesperado na ferramenta de banco de dados: {e}"
    
    # Bloco finally executado sempre, para fechar conex√£o se aberta
    finally:
        
        # Se a conex√£o foi estabelecida, fecha-a para n√£o deixar recursos abertos
        if conn:
            conn.close()

# Lista de ferramentas
tools = [query_folha_database]

# Cria o objeto para o n√≥ de ferramenta
tool_node = ToolNode(tools) 

# Define a fun√ß√£o que cria um agente ‚Äúrunnable‚Äù a partir de um LLM e um prompt de sistema
def cria_agente_runnable(llm, system_prompt):

    # Cria um template de chat prompt a partir de uma lista de mensagens
    prompt = ChatPromptTemplate.from_messages(
        [
            # Mensagem do sistema contendo as instru√ß√µes iniciais
            ("system", system_prompt),
            
            # Placeholder para inserir o hist√≥rico de mensagens trocadas
            MessagesPlaceholder(variable_name = "messages"),
        ]
    )

    # Associa as ferramentas dispon√≠veis ao LLM, criando um pipeline execut√°vel
    agent_runnable = prompt | llm.bind_tools(tools)
    
    # Retorna o agente configurado para execu√ß√£o
    return agent_runnable

# Define a fun√ß√£o do n√≥ do agente Groq respons√°vel por interagir com o CRM
def groq_agent_node(state: AgentState):

    print("\n *** Executando o N√≥ Groq (Folha de Pagamento) *** \n")

    try:

        # Inicializa o LLM Groq com o modelo, temperatura e chave de API
        # llama3-8b-8192
        llm_groq = ChatGroq(model_name="llama-3.1-8b-instant", temperature=0.2, groq_api_key=groq_api_key) 
        
        # Define o prompt do sistema com instru√ß√µes para usar a ferramenta Folha de Pagamento
        system_prompt = """Voc√™ √© um assistente de Folha de Pagamento experiente chamado Groq (modelo Llama3).
        Sua principal fun√ß√£o √© responder perguntas sobre servidores e remunera√ß√µes consultando o banco de dados da Folha de Pagamento.
        Use a ferramenta 'query_folha_database' fornecendo uma consulta SQL SELECT v√°lida para buscar as informa√ß√µes pedidas.
        Consulte a descri√ß√£o da ferramenta para ver o schema do banco de dados (tabelas: tb_servidores, tb_folha_pagamento e suas colunas).
        Seja direto e baseie suas respostas nos dados retornados pela ferramenta. Se a ferramenta retornar um erro, informe o usu√°rio.
        N√£o invente informa√ß√µes se elas n√£o estiverem no banco de dados.
        """
        
        # Cria um agente execut√°vel a partir do LLM e do prompt do sistema
        agent_runnable = cria_agente_runnable(llm_groq, system_prompt)
        
        # Informa que o agente Groq foi criado e ser√° invocado
        print("Runnable Groq (Folha de Pagamento) criado. Invocando...")
        
        # Invoca o agente com o hist√≥rico de mensagens contido no estado
        response = agent_runnable.invoke({"messages": state['messages']})
        
        # Exibe informa√ß√µes sobre o tipo de resposta e parte do seu conte√∫do
        print(f"N√≥ Groq (Folha de Pagamento) Obteve Resposta: Tipo = {type(response)}, Conte√∫do = '{response.content[:50]}...'")
        
        # Verifica se a resposta inclui chamadas de ferramentas
        if hasattr(response, 'tool_calls') and response.tool_calls:

            # Exibe quais ferramentas foram acionadas pelo agente
            print(f"N√≥ Groq (CRM) est√° chamando a ferramenta: {response.tool_calls}")
        
        # Retorna o dicion√°rio contendo as mensagens de resposta do agente
        return {"messages": [response]}

    except Exception as e:

        # Em caso de exce√ß√£o, exibe mensagem de erro no console
        print(f"!!! ERRO NO N√ì Groq (Folha de Pagamento): {e} !!!")
        
        # Mostra o erro ao usu√°rio na interface Streamlit
        st.error(f"Ocorreu um erro ao contactar a API Groq: {e}")
        
        # Cria uma mensagem de erro interna para ser retornada pelo n√≥
        error_msg = AIMessage(content = f"[ERRO INTERNO GROQ]: N√£o foi poss√≠vel processar com Groq. Detalhe: {e}", name = "ErroGroq")
        
        # Retorna o dicion√°rio contendo a mensagem de erro
        return {"messages": [error_msg]}

# Define a fun√ß√£o do n√≥ do agente OpenAI respons√°vel por interagir com o CRM
def openai_agent_node(state: AgentState):

    print("\n--- Executando N√≥ Agente OpenAI (Folha de Pagamento) ---")
    
    try:

        # Inicializa o LLM OpenAI com temperatura baixa e chave de API
        llm_openai = ChatOpenAI(temperature=0.2, openai_api_key=openai_api_key, model_name="gpt-3.5-turbo")
        
        # Define o prompt do sistema com instru√ß√µes para usar a ferramenta Folha de Pagamento
        system_prompt = """Voc√™ √© um assistente de Folha de Pagamento experiente chamado OpenAI (modelo GPT).
        Seu objetivo √© ajudar o usu√°rio com informa√ß√µes do banco de dados Folha de Pagamento.
        Utilize a ferramenta 'query_folha_database' para executar consultas SQL SELECT e buscar dados sobre servidores ou remunera√ß√µes.
        Refira-se √† descri√ß√£o da ferramenta para entender o schema do banco (tabelas: tb_servidores, tb_folha_pagamento e suas colunas).
        Seja direto e baseie suas respostas; colunas relevantes como nome, cpf_mascarado, cargo, orgao_lotacao, status, ano_mes, remuneracao_basica_bruta, verbas_indenizatorias, total_descontos, salario_liquido).
        Formule consultas SQL SELECT precisas com base na pergunta do usu√°rio.
        Apresente os resultados de forma clara. Se encontrar um erro da ferramenta, comunique-o.
        Se a informa√ß√£o n√£o estiver dispon√≠vel, indique isso claramente.
        """
        
        # Cria um agente execut√°vel a partir do LLM e do prompt do sistema
        agent_runnable = cria_agente_runnable(llm_openai, system_prompt)
        
        # Informa que o agente OpenAI foi criado e ser√° invocado
        print("Runnable OpenAI (Folha de Pagamento) criado. Invocando...")
        
        # Invoca o agente com o hist√≥rico de mensagens contido no estado
        response = agent_runnable.invoke({"messages": state['messages']})
        
        # Exibe informa√ß√µes sobre o tipo de resposta e parte do seu conte√∫do
        print(f"N√≥ OpenAI (Folha de Pagamento) Obteve Resposta: Tipo={type(response)}, Conte√∫do='{response.content[:50]}...'")
        
        # Verifica se a resposta inclui chamadas de ferramentas
        if hasattr(response, 'tool_calls') and response.tool_calls:
            
            # Exibe quais ferramentas foram acionadas pelo agente
            print(f"N√≥ OpenAI (Folha de Pagamento) est√° chamando a ferramenta: {response.tool_calls}")
        
        # Retorna o dicion√°rio contendo as mensagens de resposta do agente
        return {"messages": [response]}

    except Exception as e:
        
        # Em caso de exce√ß√£o, exibe mensagem de erro no console
        print(f"!!! ERRO NO N√ì OpenAI (Folha de Pagamento): {e} !!!")
        
        # Mostra o erro ao usu√°rio na interface Streamlit
        st.error(f"Ocorreu um erro ao contactar a API OpenAI: {e}")
        
        # Cria uma mensagem de erro interna para ser retornada pelo n√≥
        error_msg = AIMessage(content=f"[ERRO INTERNO OPENAI]: N√£o foi poss√≠vel processar com OpenAI. Detalhe: {e}", name="ErroOpenAI")
        
        # Retorna o dicion√°rio contendo a mensagem de erro
        return {"messages": [error_msg]}

# Fun√ß√£o para o n√≥ de roteamento
# A l√≥gica de roteamento estar√° na pr√≥xima fun√ß√£o
# Mesmo que ela n√£o tenha l√≥gica de processamento, ela atua como n√≥ expl√≠cito de roteamento, deixando claro no grafo onde ocorre a decis√£o central
# Em grafos de fluxo de agentes, √© uma boa pr√°tica ter n√≥s expl√≠citos que atuam como hubs ou roteadores, mesmo que n√£o modifiquem o estado
def route_junction_node(state: AgentState) -> dict:
    print("--- N√≥ de Jun√ß√£o de Roteamento (Sem Mudan√ßa de Estado) ---")
    return {}

# Define a fun√ß√£o respons√°vel por decidir para onde o roteador deve enviar a pr√≥xima mensagem
def router_logic(state: AgentState) -> str:

    print("\n--- Fun√ß√£o L√≥gica de Roteamento (Decidindo Pr√≥ximo Passo) ---")

    # Recupera a lista de mensagens do estado atual
    messages = state['messages']
    
    # Seleciona a √∫ltima mensagem, se existir
    last_message = messages[-1] if messages else None

    # Se n√£o houver nenhuma mensagem, encerra o roteamento
    if not last_message:
        print("Decis√£o L√≥gica: Sem mensagens no estado, terminando.")
        return "__end__"

    # Mostra no console informa√ß√µes sobre a √∫ltima mensagem analisada
    print(f"Roteador analisando √∫ltima mensagem: Tipo={type(last_message).__name__}, Conte√∫do='{last_message.content[:80]}...'")

    # Se a √∫ltima mensagem for de IA e contiver chamadas de ferramenta, roteia para "tools"
    if isinstance(last_message, AIMessage) and hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        print("Decis√£o L√≥gica: √öltima mensagem AI tem 'tool_calls'. Roteando para Ferramentas.")
        return "tools"

    # Se a √∫ltima mensagem for de IA sem chamadas de ferramenta, encerra o ciclo atual
    if isinstance(last_message, AIMessage):
        print("Decis√£o L√≥gica: Resposta final da IA recebida (sem tool_calls). Terminando o ciclo atual.")
        return "__end__"

    # Se a √∫ltima mensagem for humana, verifica men√ß√µes expl√≠citas a roteadores
    if isinstance(last_message, HumanMessage):
        
        # Converte o conte√∫do da mensagem para min√∫sculas para facilitar a compara√ß√£o
        user_input_current = last_message.content.lower()

        print(f"Analisando √∫ltima mensagem humana para men√ß√µes: '{user_input_current}'")
        
        # Roteia para OpenAI se houver men√ß√£o a "@openai"
        if "@openai" in user_input_current:
            print("Decis√£o L√≥gica: Roteando para OpenAI (men√ß√£o expl√≠cita na √∫ltima mensagem)")
            return "openai_agent"
        
        # Roteia para Groq se houver men√ß√£o a "@groq"
        elif "@groq" in user_input_current:
            print("Decis√£o L√≥gica: Roteando para Groq (men√ß√£o expl√≠cita na √∫ltima mensagem)")
            return "groq_agent"

    # Se a √∫ltima mensagem for resultado de ferramenta, indica roteamento alternado
    if isinstance(last_message, ToolMessage):
        print("Decis√£o L√≥gica: Resultado da ferramenta recebido, roteando para um agente (via altern√¢ncia)...")

    # Conta quantas mensagens de IA j√° foram trocadas para alternar o roteamento
    ai_message_count = sum(1 for msg in messages if isinstance(msg, AIMessage))
    
    print(f"Contagem atual de mensagens AI para altern√¢ncia: {ai_message_count}")

    # Se o n√∫mero de respostas de IA for par, roteia para Groq como padr√£o alternado
    if ai_message_count % 2 == 0:
        print(f"Decis√£o L√≥gica: Roteando para Groq (padr√£o/alternado)")
        return "groq_agent"
    
    # Caso contr√°rio, roteia para OpenAI
    else:
        print(f"Decis√£o L√≥gica: Roteando para OpenAI (padr√£o/alternado)")
        return "openai_agent"

# Define a fun√ß√£o respons√°vel por compilar o grafo de estados e transi√ß√µes do agente
def compila_grafo():

    # Cria uma inst√¢ncia de StateGraph usando AgentState como tipo de estado
    workflow = StateGraph(AgentState)

    # Adiciona o n√≥ que executa o agente OpenAI 
    workflow.add_node("openai_agent", openai_agent_node)

    # Adiciona o n√≥ que executa o agente Groq
    workflow.add_node("groq_agent", groq_agent_node)
    
    # Adiciona o n√≥ que trata a execu√ß√£o de ferramentas
    workflow.add_node("tools", tool_node)
    
    # Adiciona o n√≥ de jun√ß√£o/roteamento para decidir o pr√≥ximo passo
    workflow.add_node("router", route_junction_node)
    
    # Conecta o ponto de entrada START ao n√≥ de roteamento
    workflow.add_edge(START, "router")
    
    # Configura arestas condicionais saindo do roteador baseado na l√≥gica de roteamento
    workflow.add_conditional_edges(
        "router",
        router_logic,
        {
            "tools": "tools",
            "groq_agent": "groq_agent",
            "openai_agent": "openai_agent",
            "__end__": END
        },
    )
    
    # Conecta a sa√≠da do agente OpenAI de volta ao roteador para o pr√≥ximo ciclo
    workflow.add_edge("openai_agent", "router")

    # Conecta a sa√≠da do agente Groq de volta ao roteador para o pr√≥ximo ciclo
    workflow.add_edge("groq_agent", "router")
    
    # Conecta a sa√≠da das ferramentas de volta ao roteador para o pr√≥ximo ciclo
    workflow.add_edge("tools", "router")
    
    # Compila o workflow em um aplicativo execut√°vel
    app = workflow.compile()
    
    # Imprime no console confirma√ß√£o de sucesso na compila√ß√£o
    print("Grafo Compilado com Sucesso!")
    
    # Retorna o aplicativo resultante do grafo compilado
    return app

##### Interface de Deploy com Streamlit #####

# Verifica se o aplicativo ainda n√£o foi inicializado na sess√£o
if "app" not in st.session_state:

    # Se o arquivo do banco de dados n√£o existir, exibe erro e orienta a cria√ß√£o
    if not os.path.exists(DB_FILE):
        st.error(f"Erro: O arquivo do banco de dados '{DB_FILE}' n√£o foi encontrado.")
        st.info("Por favor, execute o script 'cria_db.py' no mesmo diret√≥rio para criar o banco de dados e depois recarregue esta p√°gina.")
        st.stop()

    # Informa que o grafo ser√° inicializado pela primeira vez
    st.write("Inicializando o grafo pela primeira vez...")

    try:
        
        # Compila o grafo e armazena na sess√£o
        st.session_state.app = compila_grafo()
        
        # Define um identificador de thread para controle interno
        st.session_state.thread_id = "streamlit_thread_folha"
        
        # Se o hist√≥rico de chat n√£o existir na sess√£o, inicializa com uma mensagem de boas-vindas
        if "chat_history" not in st.session_state:
            st.session_state.chat_history = [
                AIMessage(content="Ol√°! Sou seu assistente de Folha de Pagamento. Pergunte-me sobre servidores ou remunera√ß√µes (ex: 'Quantos servidores est√£o ativos?', 'Mostre as remunera√ß√µes do funcion√°rio Servidor 2').")
            ]
        
        # Exibe mensagem de sucesso ap√≥s inicializar o grafo
        st.success("Grafo Folha de Pagamento inicializado.")
    
    except Exception as e:
        
        # Em caso de erro cr√≠tico na constru√ß√£o do grafo, exibe mensagem de erro e a exce√ß√£o
        st.error(f"Erro cr√≠tico ao construir o grafo Folha de Pagamento: {e}")
        st.exception(e)
        
        # Interrompe a execu√ß√£o da aplica√ß√£o ap√≥s o erro
        st.stop()

# Sidebar
st.sidebar.title("Mem√≥ria")

# Expande a se√ß√£o lateral para exibir o hist√≥rico completo da conversa
with st.sidebar.expander("üìú Ver Hist√≥rico Completo da Conversa", expanded=False):
    
    # Se houver mensagens no hist√≥rico de chat na sess√£o
    if st.session_state.chat_history:
        
        # Itera sobre cada mensagem armazenada no hist√≥rico
        for i, msg in enumerate(st.session_state.chat_history):
            
            # Determina o papel da mensagem (IA, ferramenta ou usu√°rio)
            role = "ai" if isinstance(msg, AIMessage) else ("tool" if isinstance(msg, ToolMessage) else "user")
            
            # Inicializa o nome exibido do remetente como 'Usu√°rio'
            sender_display = "Usu√°rio"
            
            # Se a mensagem for da IA, ajusta o remetente conforme regras de altern√¢ncia e men√ß√µes expl√≠citas
            if role == "ai":
                
                # Conta quantas mensagens de IA ocorreram antes desta
                ai_message_index = sum(1 for m in st.session_state.chat_history[:i] if isinstance(m, AIMessage))
                
                # Verifica se h√° men√ß√£o expl√≠cita ao roteador Groq
                is_groq_explicit = "@groq" in msg.content.lower()
                
                # Verifica se h√° men√ß√£o expl√≠cita ao roteador OpenAI
                is_openai_explicit = "@openai" in msg.content.lower()
                
                # Obt√©m o nome personalizado da mensagem, se existir
                msg_name = getattr(msg, 'name', None)
                
                # Define a exibi√ß√£o do remetente seguindo condi√ß√µes de men√ß√µes e altern√¢ncia
                if is_groq_explicit or (not is_openai_explicit and ai_message_index % 2 == 0 and not msg_name):
                    sender_display = "AI (Groq/Llama3)"
                elif is_openai_explicit or (not is_groq_explicit and ai_message_index % 2 != 0 and not msg_name):
                    sender_display = "AI (OpenAI/GPT)"
                elif msg_name:
                    sender_display = f"AI ({msg_name})"
                else:
                    sender_display = "AI (Assistente)"
            
            # Se a mensagem for de ferramenta, ajusta o nome do remetente para 'Ferramenta'
            elif role == "tool":
                
                # Obt√©m o nome da ferramenta ou usa o padr√£o
                tool_name = getattr(msg, 'name', 'query_folha_database')
                sender_display = f"Ferramenta ({tool_name})"
            
            # Renderiza o cabe√ßalho do remetente
            st.markdown(f"**{sender_display}:**")
            
            # Exibe o conte√∫do da mensagem em um campo de texto somente leitura
            st.text_area(label=f"msg_{i}", value=msg.content, height=100, disabled=True, label_visibility="collapsed")
            
            # Se a mensagem for de IA e conter chamadas de ferramenta, exibe em formato JSON
            if isinstance(msg, AIMessage) and getattr(msg, 'tool_calls', None):
                st.write("*Chamada(s) de Ferramenta:*")
                st.json([{'name': tc.get('name', 'N/A'), 'args': tc.get('args', {})} for tc in msg.tool_calls])
            
            # Se a mensagem for de ferramenta e tiver ID de chamada, exibe a legenda com o ID
            if isinstance(msg, ToolMessage) and hasattr(msg, 'tool_call_id'):
                st.caption(f"ID da Chamada: {msg.tool_call_id}")
            
            # Adiciona um divisor entre mensagens
            st.divider()
    
    # Se n√£o houver mensagens no hist√≥rico, exibe mensagem informativa
    else:
        st.write("Nenhuma mensagem no hist√≥rico ainda.")

# Exibe t√≠tulo "Chat Ativo" no corpo principal do Streamlit
st.markdown("### Chat Ativo")

# Cria um container para a √°rea do chat com altura fixa de 500 pixels
container_chat = st.container(height = 500)

# Inicia o contexto para renderizar dentro do container do chat
with container_chat:

    # Itera sobre o hist√≥rico de mensagens armazenado na sess√£o
    for i, msg in enumerate(st.session_state.chat_history):
        
        # Determina o papel da mensagem: 'ai', 'tool' ou 'user'
        role = "ai" if isinstance(msg, AIMessage) else ("tool" if isinstance(msg, ToolMessage) else "user")
        
        # Define √≠cone padr√£o de avatar para usu√°rio
        avatar_icon = "üë§"
        
        # Define nome padr√£o do remetente como "Usu√°rio"
        sender_name = "Usu√°rio"
        
        # Define papel padr√£o para o componente de chat do Streamlit
        message_role_for_streamlit = "user"

        # Se a mensagem for da IA, ajusta √≠cone, nome e papel
        if role == "ai":
            
            # Define papel de mensagem para o assistente no componente de chat
            message_role_for_streamlit = "assistant"
            
            # Conta quantas mensagens de IA j√° ocorreram antes desta
            ai_message_index = sum(1 for m in st.session_state.chat_history[:i] if isinstance(m, AIMessage))
            
            # Verifica men√ß√£o expl√≠cita a "@groq" no conte√∫do da mensagem
            is_groq_explicit = "@groq" in msg.content.lower()
            
            # Verifica men√ß√£o expl√≠cita a "@openai" no conte√∫do da mensagem
            is_openai_explicit = "@openai" in msg.content.lower()
            
            # Obt√©m nome espec√≠fico da mensagem caso exista
            msg_name = getattr(msg, 'name', None)
            
            # Se for Groq ou altern√¢ncia com √≠ndice par e sem nome, define avatar Groq
            if is_groq_explicit or (not is_openai_explicit and ai_message_index % 2 == 0 and not msg_name):
                 avatar_icon = "ü¶ô"
                 sender_name = "Groq (Llama3)"
            
            # Se for OpenAI ou altern√¢ncia com √≠ndice √≠mpar e sem nome, define avatar OpenAI
            elif is_openai_explicit or (not is_groq_explicit and ai_message_index % 2 != 0 and not msg_name):
                 avatar_icon = "ü§î"
                 sender_name = "OpenAI (GPT)"
            
            # Se existir nome personalizado na mensagem, usa avatar de sistema
            elif msg_name:
                 avatar_icon = "‚ö†Ô∏è"
                 sender_name = f"Sistema ({msg_name})"
            
            # Caso contr√°rio, usa avatar gen√©rico de assistente
            else:
                 avatar_icon = "ü§ñ"
                 sender_name = "Assistente"
        
        # Se a mensagem for de ferramenta, ajusta papel, avatar e nome
        elif role == "tool":
             
             # Define papel de mensagem para o assistente no componente de chat
             message_role_for_streamlit = "assistant"
             
             # Define √≠cone de ferramenta
             avatar_icon = "üõ†Ô∏è"
             
             # Define nome do remetente como "Ferramenta"
             sender_name = "Ferramenta"

        # Renderiza cada mensagem no componente de chat com avatar e papel definidos
        with st.chat_message(message_role_for_streamlit, avatar=avatar_icon):
            
            # Se a mensagem for de ferramenta, exibe resultado com formata√ß√£o
            if role == "tool":
                
                # Obt√©m nome da ferramenta ou usa valor padr√£o
                tool_name = getattr(msg, 'name', 'query_folha_database')
                
                # Exibe t√≠tulo do resultado da ferramenta
                st.markdown(f"**Resultado Ferramenta ({tool_name})**:")
                
                # Exibe conte√∫do da ferramenta em bloco de c√≥digo
                st.code(f"{msg.content}", language=None)
                
                # Exibe legenda com o ID da chamada da ferramenta
                st.caption(f"ID Chamada: {msg.tool_call_id}")
            
            # Se a mensagem for da IA, exibe conte√∫do e chamadas de ferramenta se houver
            elif role == "ai":
                
                # Exibe nome do remetente da IA em negrito
                st.markdown(f"**{sender_name}:**")
                
                # Se existirem chamadas de ferramenta, exibe em formato JSON
                if getattr(msg, 'tool_calls', None):
                     st.write(f"*Chamando ferramenta(s):*")
                     st.json([{'name': tc.get('name', 'N/A'), 'args': tc.get('args', {})} for tc in msg.tool_calls])
                
                # Exibe o conte√∫do da mensagem da IA
                st.markdown(msg.content)
            
            # Se for mensagem do usu√°rio, exibe diretamente o texto
            else:
                
                # Exibe o conte√∫do da mensagem do usu√°rio
                st.markdown(msg.content)

# Se o usu√°rio inserir uma pergunta no chat
if prompt := st.chat_input("Fa√ßa uma pergunta sobre a Folha de Pagamento ..."):
    
    # Adiciona a mensagem humana ao hist√≥rico de chat na sess√£o
    st.session_state.chat_history.append(HumanMessage(content=prompt))
    
    # Reinicia a execu√ß√£o da aplica√ß√£o para processar a entrada
    st.rerun()

# Gerenciamento da Mem√≥ria e Inicializa√ß√£o do Estado Para os Agentes de IA
# Se existir hist√≥rico de chat e a √∫ltima mensagem for do usu√°rio
if st.session_state.chat_history and isinstance(st.session_state.chat_history[-1], HumanMessage):
    
    # Armazena a √∫ltima mensagem humana
    last_human_message = st.session_state.chat_history[-1]
    
    # Se ainda n√£o estivermos processando outra requisi√ß√£o
    if not st.session_state.get("processing_lock", False):
        
        # Ativa o bloqueio de processamento
        st.session_state["processing_lock"] = True
        
        # Prepara o estado atual com todas as mensagens
        current_state = {"messages": st.session_state.chat_history}
        
        # Exibe um spinner indicando consulta ao CRM e pensamento do agente
        with st.spinner("Consultando Folha de Pagamento e pensando..."):
            
            # Inicializa a vari√°vel de retorno do grafo
            final_state = None

            try:
                
                # Invoca o grafo a partir do estado atual
                final_state = st.session_state.app.invoke(current_state)
                
                # Se o grafo retornou um estado v√°lido contendo mensagens
                if final_state and "messages" in final_state:
                    
                    # Extrai apenas as novas mensagens geradas ap√≥s a invoca√ß√£o
                    new_messages = final_state["messages"][len(current_state["messages"]):]
                    
                    # Se houver novas mensagens, adiciona ao hist√≥rico
                    if new_messages:
                        st.session_state.chat_history.extend(new_messages)
                    else:
                        # Informa que n√£o houve novas mensagens nesta rodada
                        st.toast("O grafo n√£o retornou novas mensagens desta vez.", icon="ü§î")
                else:
                    
                    # Informa que o estado retornado foi inv√°lido
                    st.toast("O grafo retornou um estado inv√°lido.", icon="error")
                    
                    # Registra mensagem de erro interno no hist√≥rico
                    st.session_state.chat_history.append(AIMessage(content="Desculpe, ocorreu um erro interno no estado do grafo."))
            
            except Exception as e:
                
                # Exibe o erro ocorrido durante a execu√ß√£o do grafo
                st.error(f"Erro durante a execu√ß√£o do grafo: {e}")
                
                # Adiciona mensagem de erro ao hist√≥rico de chat
                st.session_state.chat_history.append(AIMessage(content=f"Desculpe, ocorreu um erro: {e}"))
            
            finally:
                
                # Libera o bloqueio de processamento
                st.session_state["processing_lock"] = False
                
                # Reinicia a aplica√ß√£o para atualizar a interface com novos dados
                st.rerun()

# T√≠tulo da barra lateral do Streamlit
st.sidebar.divider()
st.sidebar.title("Instru√ß√µes")

# Exibe instru√ß√µes para o usu√°rio na barra lateral
st.sidebar.markdown("""
Digite sua pergunta ao lado para conversar com os Agentes de IA.

Os Agentes s√£o capazes de consultar o banco de dados de Folha de Pagamento SQLite e para extrair as respostas.

Tipos de perguntas:
- **Quantos servidores est√£o ativos?**                    
- **Qual √© a remunera√ß√£o do Servidor 2?**
- **Quantos servidores ocupam o cargo de Assistente?**
- **Quantos servidores s√£o da Secretaria da Sa√∫de?**
- **Na Fazenda, quantos ervidores cupam o cargo de Assistente?**                    
- **Quantos servidores tiveram aumento?**
- **Algum servidores foram demitidos? Quais?**
- **Qual √© o valor da folha da fazenda em 202401?**
- **Qual √© o valor da folha da saude no ano de 2024?**                     
- **Fa√ßa uma simula√ß√£o da folha de pagamento da sa√∫de para maio de 2024**
- **Qual √© o valor total da folha de pagamento da secretaria da fazenda no ano de 2024?** 
- **Qual seria o valor da folha da secretaria da fazenda em 2024 se houvesse um aumento de 10% no vencimento dos servidores?**         

IA Generativa comete erros. **SEMPRE** use seu conhecimento para verificar as respostas.
""")

# Bot√£o de suporte na barra lateral que exibe mensagem ao clicar
if st.sidebar.button("Suporte"):
    st.sidebar.write("D√∫vidas? Entre em contato com o analista de sistemas respons√°vel pelo projeto.")


